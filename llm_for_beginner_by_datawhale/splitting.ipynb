{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display, Markdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 导入文本分割器\n",
    "from langchain.text_splitter import (\n",
    "    RecursiveCharacterTextSplitter,\n",
    "    CharacterTextSplitter,\n",
    ")\n",
    "\n",
    "chunk_size = 20  # 设置块大小\n",
    "chunk_overlap = 10  # 设置块重叠大小\n",
    "\n",
    "# 初始化递归字符文本分割器\n",
    "r_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=chunk_size, chunk_overlap=chunk_overlap\n",
    ")\n",
    "# 初始化字符文本分割器\n",
    "c_splitter = CharacterTextSplitter(chunk_size=chunk_size, chunk_overlap=chunk_overlap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['在AI的研究中，由于大模型规模非常大，模',\n",
       " '大模型规模非常大，模型参数很多，在大模型',\n",
       " '型参数很多，在大模型上跑完来验证参数好不',\n",
       " '上跑完来验证参数好不好训练时间成本很高，',\n",
       " '好训练时间成本很高，所以一般会在小模型上',\n",
       " '所以一般会在小模型上做消融实验来验证哪些',\n",
       " '做消融实验来验证哪些改进是有效的再去大模',\n",
       " '改进是有效的再去大模型上做实验。']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = \"在AI的研究中，由于大模型规模非常大，模型参数很多，在大模型上跑完来验证参数好不好训练时间成本很高，所以一般会在小模型上做消融实验来验证哪些改进是有效的再去大模型上做实验。\"  # 测试文本\n",
    "r_splitter.split_text(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['在AI的研究中，由于大模型规模非常大，模型参数很多，在大模型上跑完来验证参数好不好训练时间成本很高，所以一般会在小模型上做消融实验来验证哪些改进是有效的再去大模型上做实验。']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 字符文本分割器\n",
    "c_splitter.split_text(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Created a chunk of size 23, which is longer than the specified 20\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['在AI的研究中，由于大模型规模非常大',\n",
       " '由于大模型规模非常大，模型参数很多',\n",
       " '在大模型上跑完来验证参数好不好训练时间成本很高',\n",
       " '所以一般会在小模型上做消融实验来验证哪些改进是有效的再去大模型上做实验。']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 设置空格分隔符\n",
    "c_splitter = CharacterTextSplitter(\n",
    "    chunk_size=chunk_size, chunk_overlap=chunk_overlap, separator=\"，\"\n",
    ")\n",
    "c_splitter.split_text(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "177\n"
     ]
    }
   ],
   "source": [
    "# 中文版\n",
    "some_text = \"\"\"在编写文档时，作者将使用文档结构对内容进行分组。 \\\n",
    "    这可以向读者传达哪些想法是相关的。 例如，密切相关的想法\\\n",
    "    是在句子中。 类似的想法在段落中。 段落构成文档。 \\n\\n\\\n",
    "    段落通常用一个或两个回车符分隔。 \\\n",
    "    回车符是您在该字符串中看到的嵌入的“反斜杠 n”。 \\\n",
    "    句子末尾有一个句号，但也有一个空格。\\\n",
    "    并且单词之间用空格分隔\"\"\"\n",
    "\n",
    "print(len(some_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_splitter = CharacterTextSplitter(chunk_size=80, chunk_overlap=0, separator=\" \")\n",
    "\n",
    "\"\"\" \n",
    "对于递归字符分割器，依次传入分隔符列表，分别是双换行符、单换行符、空格、空字符，\n",
    "因此在分割文本时，首先会采用双分换行符进行分割，同时依次使用其他分隔符进行分割\n",
    "\"\"\"\n",
    "\n",
    "r_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=80, chunk_overlap=0, separators=[\"\\n\\n\", \"\\n\", \" \", \"\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['在编写文档时，作者将使用文档结构对内容进行分组。 这可以向读者传达哪些想法是相关的。 例如，密切相关的想法 是在句子中。 类似的想法在段落中。 段落构成文档。',\n",
       " '段落通常用一个或两个回车符分隔。 回车符是您在该字符串中看到的嵌入的“反斜杠 n”。 句子末尾有一个句号，但也有一个空格。 并且单词之间用空格分隔']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c_splitter.split_text(some_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['在编写文档时，作者将使用文档结构对内容进行分组。     这可以向读者传达哪些想法是相关的。 例如，密切相关的想法    是在句子中。 类似的想法在段落中。',\n",
       " '段落构成文档。',\n",
       " '段落通常用一个或两个回车符分隔。     回车符是您在该字符串中看到的嵌入的“反斜杠 n”。     句子末尾有一个句号，但也有一个空格。',\n",
       " '并且单词之间用空格分隔']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r_splitter.split_text(some_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['在编写文档时，作者将使用文档结构对内容进行分组。',\n",
       " '这可以向读者传达哪些想法是相关的。 例如，密切相关的想法',\n",
       " '是在句子中。 类似的想法在段落中。 段落构成文档。',\n",
       " '段落通常用一个或两个回车符分隔。',\n",
       " '回车符是您在该字符串中看到的嵌入的“反斜杠 n”。',\n",
       " '句子末尾有一个句号，但也有一个空格。',\n",
       " '并且单词之间用空格分隔']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=30, chunk_overlap=0, separators=[\"\\n\\n\", \"\\n\", \"(?<=\\。 )\", \" \", \"\"]\n",
    ")\n",
    "r_splitter.split_text(some_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['foo', ' bar', ' b', 'az', 'zy', 'foo']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 使用token分割器进行分割，\n",
    "# 将块大小设为1，块重叠大小设为0，相当于将任意字符串分割成了单个Token组成的列\n",
    "from langchain.text_splitter import TokenTextSplitter\n",
    "\n",
    "text_splitter = TokenTextSplitter(chunk_size=1, chunk_overlap=0)\n",
    "text = \"foo bar bazzyfoo\"\n",
    "text_splitter.split_text(text)\n",
    "# 注：目前 LangChain 基于 Token 的分割器还不支持中文"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义一个Markdown文档\n",
    "\n",
    "from langchain.document_loaders import NotionDirectoryLoader  # Notion加载器\n",
    "from langchain.text_splitter import MarkdownHeaderTextSplitter  # markdown分割器\n",
    "\n",
    "markdown_document = \"\"\"# Title\\n\\n \\\n",
    "## 第一章\\n\\n \\\n",
    "李白乘舟将欲行\\n\\n 忽然岸上踏歌声\\n\\n \\\n",
    "### Section \\n\\n \\\n",
    "桃花潭水深千尺 \\n\\n \n",
    "## 第二章\\n\\n \\\n",
    "不及汪伦送我情\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "第一个块\n",
      "page_content='李白乘舟将欲行  \n",
      "忽然岸上踏歌声' metadata={'Header 1': 'Title', 'Header 2': '第一章'}\n",
      "第二个块\n",
      "page_content='桃花潭水深千尺' metadata={'Header 1': 'Title', 'Header 2': '第一章', 'Header 3': 'Section'}\n"
     ]
    }
   ],
   "source": [
    "# 定义想要分割的标题列表和名称\n",
    "headers_to_split_on = [\n",
    "    (\"#\", \"Header 1\"),\n",
    "    (\"##\", \"Header 2\"),\n",
    "    (\"###\", \"Header 3\"),\n",
    "]\n",
    "\n",
    "markdown_splitter = MarkdownHeaderTextSplitter(\n",
    "    headers_to_split_on=headers_to_split_on\n",
    ")  # message_typemessage_type\n",
    "md_header_splits = markdown_splitter.split_text(markdown_document)\n",
    "\n",
    "print(\"第一个块\")\n",
    "print(md_header_splits[0])\n",
    "print(\"第二个块\")\n",
    "print(md_header_splits[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "page_content='Saying goodbye to Blendle (from a colleague) and to a colleague (from Blendle) is a very normal and natural thing. When done right, it can even be a beautiful thing.  \n",
      "We advise you to read the backdrop below first, but feel free to jump in right away with the 'Here's what you can do'-section :). General note: you do not have to do this alone, so please ask for advice and help!  \n",
      "- **Backdrop**  \n",
      "Saying goodbye to Blendle (from a colleague) and to a colleague (from Blendle) is a very normal and natural thing. When done right, it can even be a beautiful thing.  \n",
      "Saying goodbye to people is also an important part of keeping your team on the right track. Firing can even be a part of your [Personnel Planning](https://www.notion.so/Hiring-451bbcfe8d9b49438c0633326bb7af0a?pvs=21). The most common situation will be when you think someone is no longer a good match with Blendle for whatever reason. This doesn't happen overnight, so try to spot situations where this is happening.  \n",
      "To make things clear: HR and Rick and Alex will help you with this, but we want this to be on your agenda. HR will take care of the process and paper- and legal work. Rick and Alex will help with the tough conversations. **The most important work happens months before that and that's where you come in.**  \n",
      "Why? You actually work with your people and see how they are really doing. You have 1on1's, off-sites, projects and feedback sessions together. All the information flows to you as a lead :).' metadata={'Header 1': 'Firing'}\n"
     ]
    }
   ],
   "source": [
    "# 加载数据库的内容\n",
    "loader = NotionDirectoryLoader(\"../docs/Notion_DB\")\n",
    "docs = loader.load()\n",
    "txt = \" \".join([d.page_content for d in docs])  # 拼接文档\n",
    "\n",
    "headers_to_split_on = [\n",
    "    (\"#\", \"Header 1\"),\n",
    "    (\"##\", \"Header 2\"),\n",
    "]\n",
    "# 加载文档分割器\n",
    "markdown_splitter = MarkdownHeaderTextSplitter(headers_to_split_on=headers_to_split_on)\n",
    "\n",
    "md_header_splits = markdown_splitter.split_text(txt)  # 分割文本内容\n",
    "\n",
    "print(md_header_splits[0])  # 分割结果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The first chunk\n",
      "page_content='Hi this is Jim  \n",
      "Hi this is Joe  \n",
      "### Section  \n",
      "Hi this is Lance' metadata={'Header 1': 'Title', 'Header 2': 'Chapter 1'}\n",
      "The second chunk\n",
      "page_content='Hi this is Molly' metadata={'Header 1': 'Title', 'Header 2': 'Chapter 2'}\n"
     ]
    }
   ],
   "source": [
    "# 定义一个Markdown文档\n",
    "\n",
    "from langchain.document_loaders import NotionDirectoryLoader  # Notion加载器\n",
    "from langchain.text_splitter import MarkdownHeaderTextSplitter  # markdown分割器\n",
    "\n",
    "markdown_document = \"\"\"# Title\\n\\n \\\n",
    "## Chapter 1\\n\\n \\\n",
    "Hi this is Jim\\n\\n Hi this is Joe\\n\\n \\\n",
    "### Section \\n\\n \\\n",
    "Hi this is Lance \\n\\n \n",
    "## Chapter 2\\n\\n \\\n",
    "Hi this is Molly\"\"\"\n",
    "\n",
    "# 初始化Markdown标题文本分割器，分割Markdown文档\n",
    "markdown_splitter = MarkdownHeaderTextSplitter(headers_to_split_on=headers_to_split_on)\n",
    "md_header_splits = markdown_splitter.split_text(markdown_document)\n",
    "\n",
    "print(\"The first chunk\")\n",
    "print(md_header_splits[0])\n",
    "# Document(page_content='Hi this is Jim  \\nHi this is Joe', metadata={'Header 1': 'Title', 'Header 2': 'Chapter 1'})\n",
    "print(\"The second chunk\")\n",
    "print(md_header_splits[1])\n",
    "# Document(page_content='Hi this is Lance', metadata={'Header 1': 'Title', 'Header 2': 'Chapter 1', 'Header 3': 'Section'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
